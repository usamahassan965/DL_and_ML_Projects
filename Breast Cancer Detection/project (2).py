# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r6MwGVkFZEHG--dBFuV_DnEAbe4tpxw2

## Importing the libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats

from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel

# sklearn
from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve,roc_auc_score

# Logistic Regression , KNN , SVM
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegressionCV
from lightgbm import LGBMClassifier
#from catboost import CatBoostClassifier

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout

"""## Importing the data"""

df = pd.read_csv('data.csv')
df.head()

### Information about features rows,memory usage and data types
df.info()

### Shape of the dataset having 32 columns and 569 rows
df.shape

### Statistical analysis of all columns containing mean , median , etc.
df.describe(include='all')

# drop useless columns
df.drop(['id','Unnamed: 32'], axis=1, inplace=True)
df.head(3)

df.groupby(by='diagnosis').mean()

"""## Visualizing the data"""

plt.rcParams['figure.max_open_warning'] = 31

for i in range(len(df.columns)):
  sns.displot(df,x=df.columns[i],hue='diagnosis')

### Boxplot checking outliers
plt.figure(figsize=(6,6),dpi=100)
sns.boxplot(data=df,orient='h')

# ### Bivariate Analysis

# In[18]:


x_col = 'diagnosis'
y_cols = list(df.drop('diagnosis',axis=1).columns)

for col in y_cols:
    figure = plt.figure(dpi=100)
    ax = plt.gca()
    rgb = np.random.rand(3,)
    ax.scatter(df[x_col], df[col],c=[rgb])
    ax.set_xlabel(x_col)
    ax.set_ylabel(col)
    ax.set_title("{} vs {}".format(x_col,col),fontdict={'fontsize':20})

    plt.legend(labels=col)
    plt.show()

# ## Multivariate Analysis
# - Correlation Heatmap

# In[19]:


plt.figure(figsize=(8,9),dpi=100)
sns.heatmap(df.corr())

# ## **Handling Missing Values**

# In[20]:


### Checking missing values for all columns
df.isnull().sum()

### Mapping target column to 0 and 1
df['diagnosis'] = df['diagnosis'].map({'M':0,'B':1})
df.head()

### Value counts of target column
df['diagnosis'].value_counts()

# ## **Handling Numerical Variables**

# In[24]:


### Plotting distribution graph and QQ-Plot
for i in range(len(df.columns)):
  plt.figure(figsize=(8,3),dpi=100)
  plt.subplot(121)
  sns.distplot(df[df.columns[i]])
  plt.title(df.columns[i])
  plt.subplot(122)
  stats.probplot(df[df.columns[i]], dist="norm", plot=plt)
  plt.title('QQ plot '+df.columns[i])

  plt.show()

# ### **Detecting Outliers and Removal using Z-score (Capping Method)**

# In[25]:


### Appending upper and lower limit for all columns
upper_limit = []
lower_limit = []
for i in range(len(df.columns)):
  upper_limit.append(df[df.columns[i]].mean() + 3*df[df.columns[i]].std())
  lower_limit.append(df[df.columns[i]].mean() - 3*df[df.columns[i]].std())

### Replacing all limit values to their relative columns
for i in range(len(df.columns)):
  df[df.columns[i]] = np.where(
    df[df.columns[i]]>upper_limit[i],
    upper_limit[i],
    np.where(
        df[df.columns[i]]<lower_limit[i],
        lower_limit[i],
        df[df.columns[i]]
    )
)

plt.figure(figsize=(6,6),dpi=100)
sns.boxplot(data=df,orient='h')

"""## Splitting data into X,y Variables"""

X = df.drop('diagnosis',axis=1)
Y = df['diagnosis']

# ## **Splitting X,Y into training and testing sets**

# In[29]:


X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.30,random_state=101)

X_train.shape, X_test.shape

"""## Feature Scaling"""

# ## **Feature Scaling**

# In[30]:


scaler = StandardScaler()

# fit the scaler to the train set, it will learn the parameters
scaler.fit(X_train)

# transform train and test sets
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

### Mean of all columns
scaler.mean_

X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)
np.round(X_train.describe(), 1)

"""## Model Building

### Logistic Regression CV
"""

# ## **Model Building**

# ### LogisticRegressionCV

# In[54]:


log_model = LogisticRegressionCV(max_iter=150)
log_model.fit(X_train_scaled,y_train)

"""## Evaluation of Model"""

y_pred = log_model.predict(X_test_scaled)

cm = confusion_matrix(y_test,y_pred)
fig, ax = plt.subplots(figsize=(12, 8))
ax = sns.heatmap(cm, annot=True, cmap='GnBu_r', fmt='g')

ax.set_title('Seaborn Confusion Matrix with labels\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['True','False'])
ax.yaxis.set_ticklabels(['True','False'])

## Display the visualization of the Confusion Matrix.
plt.show()

clf_report = classification_report(y_test,
                                   y_pred,
                                   target_names=[0,1],
                                   output_dict=True)
sns.heatmap(pd.DataFrame(clf_report).T, annot=True,cmap='GnBu_r', fmt='g')

"""### Support Vector Machines"""

# ## Support Vector Machines

# In[24]:


# an initial SVM model with linear kernel   
svm_linear = SVC(kernel='linear')

# fit
svm_linear.fit(X_train_scaled, y_train)

"""### Evaluation of SVM Model"""

y_pred = svm_linear.predict(X_test_scaled)

cm = confusion_matrix(y_test,y_pred)
fig, ax = plt.subplots(figsize=(12, 8))
ax = sns.heatmap(cm, annot=True, cmap='PuBu', fmt='g')

ax.set_title('Seaborn Confusion Matrix with labels\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['True','False'])
ax.yaxis.set_ticklabels(['True','False'])

## Display the visualization of the Confusion Matrix.
plt.show()

# - Classification Report of SVM Model

# In[27]:


clf_report = classification_report(y_test,
                                   y_pred,
                                   target_names=[0,1],
                                   output_dict=True)
sns.heatmap(pd.DataFrame(clf_report).T, annot=True,cmap='PuBu', fmt='g')

# Hyper-Parameter Tuning with SVM

# In[24]:


parameters = {'C':np.arange(0.001,50,0.5), 
             'gamma': [1e-5,1e-4,1e-3,1e-2,1e-1,1e0],
              'kernel': ['linear','rbf']}

# instantiate a model 
svc_grid_search = SVC()

# create a classifier to perform grid search
clf = GridSearchCV(svc_grid_search, param_grid=parameters, scoring='accuracy',return_train_score=True,n_jobs=-1)

# fit
clf.fit(X_train_scaled, y_train)

cv_results = pd.DataFrame(clf.cv_results_)
cv_results.head(3)


# In[26]:

# plotting accuracies with max_depth
plt.figure()
plt.plot(cv_results["param_C"], 
         cv_results["mean_train_score"], 
         label="training accuracy")
plt.plot(cv_results["param_C"], 
         cv_results["mean_test_score"], 
         label="test accuracy")
plt.xlabel("param_C")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# converting C to numeric type for plotting on x-axis
cv_results['param_C'] = cv_results['param_C'].astype('int')

# # plotting
plt.figure(figsize=(16,6))

# subplot 1/3
plt.subplot(131)
gamma_01 = cv_results[cv_results['param_gamma']==0.01]

plt.plot(gamma_01["param_C"], gamma_01["mean_test_score"])
plt.plot(gamma_01["param_C"], gamma_01["mean_train_score"])
plt.xlabel('C')
plt.ylabel('Accuracy')
plt.title("Gamma=0.01")
plt.ylim([0.60, 1])
plt.legend(['test accuracy', 'train accuracy'], loc='lower right')
plt.xscale('log')

# subplot 2/3
plt.subplot(132)
gamma_001 = cv_results[cv_results['param_gamma']==0.001]

plt.plot(gamma_001["param_C"], gamma_001["mean_test_score"])
plt.plot(gamma_001["param_C"], gamma_001["mean_train_score"])
plt.xlabel('C')
plt.ylabel('Accuracy')
plt.title("Gamma=0.001")
plt.ylim([0.60, 1])
plt.legend(['test accuracy', 'train accuracy'], loc='lower right')
plt.xscale('log')


# subplot 3/3
plt.subplot(133)
gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]

plt.plot(gamma_0001["param_C"], gamma_0001["mean_test_score"])
plt.plot(gamma_0001["param_C"], gamma_0001["mean_train_score"])
plt.xlabel('C')
plt.ylabel('Accuracy')
plt.title("Gamma=0.0001")
plt.ylim([0.60, 1])
plt.legend(['test accuracy', 'train accuracy'], loc='lower right')
plt.xscale('log')

plt.show()

clf.best_params_,clf.best_score_

best_SVM = SVC(C=4.001,gamma=0.01,kernel='rbf')
best_SVM.fit(X_train_scaled,y_train)

cm = confusion_matrix(y_test,y_pred)
fig, ax = plt.subplots(figsize=(12, 8))
ax = sns.heatmap(cm, annot=True, cmap='PuRd', fmt='g')

ax.set_title('Seaborn Confusion Matrix with labels\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['True','False'])
ax.yaxis.set_ticklabels(['True','False'])

## Display the visualization of the Confusion Matrix.
plt.show()

clf_report = classification_report(y_test,
                                   y_pred,
                                   target_names=[0,1],
                                   output_dict=True)
sns.heatmap(pd.DataFrame(clf_report).T, annot=True,cmap='PuRd', fmt='g')

"""### **Deep Neural Network**

### Model Building
"""

# Initialising the ANN
ANN_model = Sequential()
ANN_model.add(Dense(128, activation='relu',input_dim=X_train_scaled.shape[1]))
ANN_model.add(Dense(64, activation='relu'))
ANN_model.add(Dense(32, activation='relu'))
ANN_model.add(Dense(1, activation='sigmoid'))

ANN_model.summary()

# Compiling the ANN
ANN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Fitting the ANN to the Training set
history = ANN_model.fit(X_train, y_train,epochs=30,validation_data=(X_test,y_test))
# Long scroll ahead but worth
# The batch size and number of epochs have been set using trial and error.

# Predicting the Test set results
y_pred = ANN_model.predict(X_test)
y_pred = (y_pred > 0.5)

def plot_learning_curve(history):
    
    plt.figure(figsize=(10,6))
    
    #model accuracy
    plt.subplot(1,2,1)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')

    # model loss
    plt.subplot(1,2,2)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')

plot_learning_curve(history)

model_ls = []
for model in [best_SVM,log_model,ANN_model]:
  if model == ANN_model:
    model_ls.append(model.evaluate(X_test_scaled,y_test)[0])
  else:
    model_ls.append(model.score(X_test_scaled,y_test))
model_score = pd.DataFrame(model_ls,columns=['Accuracy'],index= ['Tuned_SVM','LogisticRegressionCV','Artificial Neural Network'])


# In[59]:


model_score